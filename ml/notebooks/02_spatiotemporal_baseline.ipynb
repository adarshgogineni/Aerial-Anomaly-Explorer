{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UAP Explorer - Spatiotemporal Baseline & Anomaly Detection\n",
    "\n",
    "This notebook creates a baseline model for expected sighting counts per grid cell and time period,\n",
    "then identifies spatiotemporal anomalies.\n",
    "\n",
    "## Objectives\n",
    "1. Aggregate sightings by spatial grid and time windows\n",
    "2. Engineer features for baseline prediction\n",
    "3. Train a model to predict expected sighting counts\n",
    "4. Compute anomaly scores (z-scores/residuals)\n",
    "5. Export grid-level anomaly scores for frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set style for plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "data_path = Path('../data/processed/cleaned_sightings.parquet')\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Cleaned data not found at {data_path}.\\n\"\n",
    "        \"Please run scripts/clean_data.py first.\"\n",
    "    )\n",
    "\n",
    "df = pd.read_parquet(data_path)\n",
    "\n",
    "print(f\"âœ“ Loaded {len(df):,} cleaned sightings\")\n",
    "print(f\"âœ“ Date range: {df['year'].min():.0f} - {df['year'].max():.0f}\")\n",
    "print(f\"âœ“ Grid cells: {df['grid_id'].nunique():,}\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spatiotemporal Aggregation\n",
    "\n",
    "Aggregate sightings by:\n",
    "- **Spatial**: 1Â° x 1Â° grid cells (already computed as grid_id)\n",
    "- **Temporal**: Monthly windows (year_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert year_month from Period to string for aggregation\n",
    "df['year_month_str'] = df['year_month'].astype(str)\n",
    "\n",
    "# Aggregate by grid cell and month\n",
    "aggregated = df.groupby(['grid_id', 'grid_lat', 'grid_lon', 'year', 'month', 'year_month_str']).agg({\n",
    "    'id': 'count',  # Count of sightings\n",
    "}).reset_index()\n",
    "\n",
    "aggregated.columns = ['grid_id', 'grid_lat', 'grid_lon', 'year', 'month', 'year_month', 'count']\n",
    "\n",
    "print(f\"âœ“ Aggregated to {len(aggregated):,} grid-time cells\")\n",
    "print(f\"âœ“ Unique grid cells: {aggregated['grid_id'].nunique():,}\")\n",
    "print(f\"âœ“ Time range: {aggregated['year'].min():.0f}-{aggregated['year'].max():.0f}\")\n",
    "print(f\"\\nSample aggregated data:\")\n",
    "aggregated.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of counts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of counts\n",
    "axes[0].hist(aggregated['count'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Sightings per Grid-Month')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Sighting Counts')\n",
    "axes[0].axvline(aggregated['count'].median(), color='red', linestyle='--', label=f'Median: {aggregated[\"count\"].median():.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Log-scale histogram\n",
    "axes[1].hist(aggregated['count'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Sightings per Grid-Month')\n",
    "axes[1].set_ylabel('Frequency (log scale)')\n",
    "axes[1].set_title('Distribution of Sighting Counts (Log Scale)')\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCount statistics:\")\n",
    "print(aggregated['count'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering for Baseline Model\n",
    "\n",
    "Create features to predict expected sighting counts:\n",
    "- Temporal: year, month, seasonality\n",
    "- Spatial: grid location\n",
    "- Historical: lagged counts (autoregressive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complete time series for each grid cell\n",
    "# This ensures we have entries for all months, even if count is 0\n",
    "\n",
    "# Get all unique combinations of grid cells and months\n",
    "all_grids = aggregated['grid_id'].unique()\n",
    "all_months = pd.date_range(\n",
    "    start=f\"{aggregated['year'].min()}-{aggregated['month'].min():02d}-01\",\n",
    "    end=f\"{aggregated['year'].max()}-{aggregated['month'].max():02d}-01\",\n",
    "    freq='MS'\n",
    ")\n",
    "\n",
    "# For simplicity, we'll work with the existing aggregated data\n",
    "# In production, you might want to fill missing months with 0 counts\n",
    "\n",
    "# Add seasonality features\n",
    "aggregated['month_sin'] = np.sin(2 * np.pi * aggregated['month'] / 12)\n",
    "aggregated['month_cos'] = np.cos(2 * np.pi * aggregated['month'] / 12)\n",
    "\n",
    "# Add year trend (normalized)\n",
    "year_min = aggregated['year'].min()\n",
    "year_max = aggregated['year'].max()\n",
    "aggregated['year_normalized'] = (aggregated['year'] - year_min) / (year_max - year_min)\n",
    "\n",
    "# Add historical count features (lagged)\n",
    "# Sort by grid and time\n",
    "aggregated = aggregated.sort_values(['grid_id', 'year', 'month'])\n",
    "\n",
    "# Create lag features (previous month's count)\n",
    "aggregated['count_lag1'] = aggregated.groupby('grid_id')['count'].shift(1)\n",
    "aggregated['count_lag3'] = aggregated.groupby('grid_id')['count'].shift(3)  # 3 months ago\n",
    "aggregated['count_lag12'] = aggregated.groupby('grid_id')['count'].shift(12)  # Same month last year\n",
    "\n",
    "# Fill NaN lags with 0 (for early months)\n",
    "aggregated['count_lag1'] = aggregated['count_lag1'].fillna(0)\n",
    "aggregated['count_lag3'] = aggregated['count_lag3'].fillna(0)\n",
    "aggregated['count_lag12'] = aggregated['count_lag12'].fillna(0)\n",
    "\n",
    "# Historical average count for this grid cell\n",
    "grid_avg = aggregated.groupby('grid_id')['count'].transform('mean')\n",
    "aggregated['grid_avg_count'] = grid_avg\n",
    "\n",
    "print(\"âœ“ Feature engineering complete\")\n",
    "print(f\"\\nFeatures created:\")\n",
    "print(f\"  - month_sin, month_cos (seasonality)\")\n",
    "print(f\"  - year_normalized (trend)\")\n",
    "print(f\"  - count_lag1, count_lag3, count_lag12 (autoregressive)\")\n",
    "print(f\"  - grid_avg_count (historical average)\")\n",
    "print(f\"\\nDataset shape: {aggregated.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Baseline Prediction Model\n",
    "\n",
    "Use Gradient Boosting to predict expected sighting counts based on:\n",
    "- Location (grid_lat, grid_lon)\n",
    "- Time features (year, month, seasonality)\n",
    "- Historical counts (lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "feature_cols = [\n",
    "    'grid_lat', 'grid_lon',\n",
    "    'year_normalized', 'month',\n",
    "    'month_sin', 'month_cos',\n",
    "    'count_lag1', 'count_lag3', 'count_lag12',\n",
    "    'grid_avg_count'\n",
    "]\n",
    "\n",
    "X = aggregated[feature_cols]\n",
    "y = aggregated['count']\n",
    "\n",
    "# Split into train and test\n",
    "# Use temporal split: train on earlier data, test on later data\n",
    "split_year = 2010\n",
    "train_mask = aggregated['year'] < split_year\n",
    "test_mask = aggregated['year'] >= split_year\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "print(f\"Training data: {len(X_train):,} samples (before {split_year})\")\n",
    "print(f\"Test data: {len(X_test):,} samples ({split_year} and after)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Gradient Boosting model\n",
    "print(\"Training Gradient Boosting model...\")\n",
    "\n",
    "model = GradientBoostingRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"âœ“ Model training complete\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\nðŸ“Š Model Performance:\")\n",
    "print(f\"  Train RÂ²: {train_r2:.3f}\")\n",
    "print(f\"  Test RÂ²: {test_r2:.3f}\")\n",
    "print(f\"  Train MAE: {train_mae:.2f}\")\n",
    "print(f\"  Test MAE: {test_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance for Sighting Count Prediction')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "print(feature_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot - Train\n",
    "axes[0].scatter(y_train, y_pred_train, alpha=0.3, s=10)\n",
    "axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Count')\n",
    "axes[0].set_ylabel('Predicted Count')\n",
    "axes[0].set_title(f'Training Set (RÂ² = {train_r2:.3f})')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot - Test\n",
    "axes[1].scatter(y_test, y_pred_test, alpha=0.3, s=10)\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Actual Count')\n",
    "axes[1].set_ylabel('Predicted Count')\n",
    "axes[1].set_title(f'Test Set (RÂ² = {test_r2:.3f})')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compute Anomaly Scores\n",
    "\n",
    "Calculate anomaly scores as standardized residuals (z-scores):\n",
    "- Residual = Actual - Predicted\n",
    "- Z-score = (Residual - Mean) / StdDev\n",
    "\n",
    "High positive z-scores indicate more sightings than expected (anomalies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on full dataset\n",
    "aggregated['predicted_count'] = model.predict(X)\n",
    "\n",
    "# Calculate residuals\n",
    "aggregated['residual'] = aggregated['count'] - aggregated['predicted_count']\n",
    "\n",
    "# Calculate z-scores (standardized residuals)\n",
    "residual_mean = aggregated['residual'].mean()\n",
    "residual_std = aggregated['residual'].std()\n",
    "aggregated['anomaly_score_cell'] = (aggregated['residual'] - residual_mean) / residual_std\n",
    "\n",
    "print(\"âœ“ Anomaly scores computed\")\n",
    "print(f\"\\nAnomaly score statistics:\")\n",
    "print(aggregated['anomaly_score_cell'].describe())\n",
    "\n",
    "# Find top anomalies\n",
    "top_anomalies = aggregated.nlargest(10, 'anomaly_score_cell')[[\n",
    "    'grid_id', 'year_month', 'count', 'predicted_count', 'anomaly_score_cell'\n",
    "]]\n",
    "\n",
    "print(\"\\nðŸ”¥ Top 10 Anomalous Grid-Time Cells:\")\n",
    "print(top_anomalies.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize anomaly score distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(aggregated['anomaly_score_cell'], bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Anomaly Score (Z-Score)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Anomaly Scores')\n",
    "axes[0].axvline(0, color='red', linestyle='--', label='Expected (0)')\n",
    "axes[0].axvline(2, color='orange', linestyle='--', label='2Ïƒ threshold')\n",
    "axes[0].axvline(-2, color='orange', linestyle='--')\n",
    "axes[0].legend()\n",
    "\n",
    "# Q-Q plot to check if residuals are normally distributed\n",
    "stats.probplot(aggregated['anomaly_score_cell'], dist=\"norm\", plot=axes[1])\n",
    "axes[1].set_title('Q-Q Plot of Anomaly Scores')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Count anomalies by threshold\n",
    "anomaly_threshold = 2.0  # 2 standard deviations\n",
    "high_anomalies = (aggregated['anomaly_score_cell'] > anomaly_threshold).sum()\n",
    "low_anomalies = (aggregated['anomaly_score_cell'] < -anomaly_threshold).sum()\n",
    "\n",
    "print(f\"\\nAnomalies (|z| > {anomaly_threshold}):\")\n",
    "print(f\"  High anomalies (more than expected): {high_anomalies:,}\")\n",
    "print(f\"  Low anomalies (less than expected): {low_anomalies:,}\")\n",
    "print(f\"  Total: {high_anomalies + low_anomalies:,} ({(high_anomalies + low_anomalies) / len(aggregated) * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Spatiotemporal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap: Average anomaly score by grid cell\n",
    "grid_anomaly = aggregated.groupby(['grid_lat', 'grid_lon'])['anomaly_score_cell'].mean().reset_index()\n",
    "\n",
    "# Create pivot table for heatmap\n",
    "pivot = grid_anomaly.pivot(index='grid_lat', columns='grid_lon', values='anomaly_score_cell')\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.heatmap(pivot, cmap='RdBu_r', center=0, robust=True, cbar_kws={'label': 'Avg Anomaly Score'})\n",
    "plt.title('Average Anomaly Score by Grid Cell (Spatial Heatmap)')\n",
    "plt.xlabel('Longitude Grid')\n",
    "plt.ylabel('Latitude Grid')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series: Average anomaly score over time\n",
    "temporal_anomaly = aggregated.groupby('year')['anomaly_score_cell'].mean()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(temporal_anomaly.index, temporal_anomaly.values, marker='o', linewidth=2)\n",
    "plt.axhline(0, color='red', linestyle='--', label='Expected baseline')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Anomaly Score')\n",
    "plt.title('Temporal Trend of Anomaly Scores')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Results\n",
    "\n",
    "Save the aggregated data with anomaly scores for use in:\n",
    "- Task 2.5: Per-report anomaly scoring (merge back)\n",
    "- Frontend: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns to export\n",
    "export_cols = [\n",
    "    'grid_id', 'grid_lat', 'grid_lon',\n",
    "    'year', 'month', 'year_month',\n",
    "    'count',\n",
    "    'predicted_count',\n",
    "    'residual',\n",
    "    'anomaly_score_cell'\n",
    "]\n",
    "\n",
    "output_path = Path('../data/processed/grid_time_anomalies.parquet')\n",
    "aggregated[export_cols].to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"âœ“ Exported {len(aggregated):,} grid-time cells to:\")\n",
    "print(f\"  {output_path}\")\n",
    "print(f\"\\nâœ… Task 2.3 Complete!\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"  1. Review the anomaly scores and visualizations above\")\n",
    "print(f\"  2. Proceed to Task 2.4: Text embeddings & clustering\")\n",
    "print(f\"  3. Or explore specific anomalous regions in detail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
